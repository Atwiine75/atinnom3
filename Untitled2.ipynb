{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 408
        },
        "id": "Mp7DGhnPr-Hy",
        "outputId": "070664dd-9d88-4cd2-f492-f03ebd86ae77"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: '/content/drive/MyDrive/https://drive.google.com/file/d/1fjMPpLnb0RvNdgBizDUs9TpZwtCjqTOs/view?usp=drive_link.csv'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-13-67ab0ea66304>\u001b[0m in \u001b[0;36m<cell line: 10>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;31m# upload and read csv file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mdrive\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0mdf\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive/MyDrive/https://drive.google.com/file/d/1fjMPpLnb0RvNdgBizDUs9TpZwtCjqTOs/view?usp=drive_link.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive/My Drive/https:/drive.google.com/drive/folders/1bKmYkO4ldrXrP0TND1rhdVNndFe3D6Bf?usp=drive_link.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m    910\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    911\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 912\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    913\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    914\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    575\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    576\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 577\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    578\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    579\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1405\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1406\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1407\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1408\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1409\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1659\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1660\u001b[0m                     \u001b[0mmode\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m\"b\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1661\u001b[0;31m             self.handles = get_handle(\n\u001b[0m\u001b[1;32m   1662\u001b[0m                 \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1663\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    857\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    858\u001b[0m             \u001b[0;31m# Encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 859\u001b[0;31m             handle = open(\n\u001b[0m\u001b[1;32m    860\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    861\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/drive/MyDrive/https://drive.google.com/file/d/1fjMPpLnb0RvNdgBizDUs9TpZwtCjqTOs/view?usp=drive_link.csv'"
          ]
        }
      ],
      "source": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.impute import SimpleImputer\n",
        "\n",
        "# Load the data\n",
        "train_data = pd.read_csv('tz_train.csv')\n",
        "test_data = pd.read_csv('tz_test.csv')\n",
        "\n",
        "# read the imported data\n",
        "train_df=pd.DataFrame(train_data)\n",
        "test_df=pd.DataFrame(test_data)\n",
        "#print(\"dataset size: \", train_df.size)\n",
        "#print(train_df)\n",
        "#print(test_df)\n",
        "\n",
        "\n",
        "\n",
        "# fill missing values\n",
        "#train_data['travel_with'].fillna('Alone')\n",
        "train_data.fillna({'travel_with':'Alone'},inplace=True)\n",
        "test_data.fillna({'travel_with':'Alone'},inplace=True)\n",
        "\n",
        "#check the number of null value\n",
        "print(train_df.isnull().sum())\n",
        "\n",
        "#print(train_data.iloc[4])\n",
        "#print(train_data.iloc[20])\n",
        "#print(train_data.iloc[21])\n",
        "\n",
        "#remove rows with invalid data\n",
        "#train_data.dropna(24-Jan,inplace=True)\n",
        "train_data[train_data['age_group'] !='24-Jan']\n",
        "test_data[test_data['age_group'] !='24-Jan']\n",
        "\n",
        "#remove rows which are empty\n",
        "train_df.dropna(axis=0,inplace=True)\n",
        "test_df.dropna(axis=0,inplace=True)\n",
        "\n",
        "train_df.dropna(subset=['total_male','total_female','most_impressing','total_cost'],inplace=True)\n",
        "test_df.dropna(subset=['total_male','total_female','most_impressing'],inplace=True)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "#print the new data set\n",
        "#print(train_df.iloc[4])\n",
        "#print(train_data.iloc[20])\n",
        "#print(train_data.iloc[21])\n",
        "\n",
        "# Remove unnecessary columns\n",
        "train_df = train_df.drop(['ID','country', 'first_trip_tz', 'most_impressing'], axis=1)\n",
        "test_df = test_df.drop(['ID','country', 'first_trip_tz', 'most_impressing'], axis=1)\n",
        "#print(train_df.iloc[4])\n",
        "\n",
        "# Separate features and target variable\n",
        "X = train_df.drop('total_cost', axis=1)\n",
        "y = train_df['total_cost']\n",
        "\n",
        "# Split the data into training and validation sets\n",
        "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Handle missing values\n",
        "numerical_cols = ['total_male', 'total_female','night_mainland','night_zanzibar']\n",
        "categorical_cols = [ 'age_group','travel_with','purpose','main_activity','info_source','tour_arrangement','package_transport_int','package_accomodation','package_food','package_transport_tz',\n",
        "                    'package_sightseeing','package_guided_tour','package_insurance','payment_mode']\n",
        "\n",
        "indices_to_drop=train_df[train_data['age_group']=='24-Jan'].index\n",
        "df=train_df.drop(indices_to_drop)\n",
        "print(df)\n",
        "\n",
        "#print(train_data['night_mainland'].unique())\n",
        "#print(train_data['night_zanzibar'].unique())\n",
        "#print(train_data['total_cost'].unique())\n",
        "print(train_data['age_group'].unique())\n",
        "print(train_data['total_male'].unique())\n",
        "print(train_data['total_female'].unique())\n",
        "print(train_data['travel_with'].unique())\n",
        "print(train_data['purpose'].unique())\n",
        "print(train_data['main_activity'].unique())\n",
        "print(train_data['info_source'].unique())\n",
        "print(train_data['tour_arrangement'].unique())\n",
        "print(train_data['package_transport_int'].unique())\n",
        "print(train_data['package_accomodation'].unique())\n",
        "print(train_data['package_food'].unique())\n",
        "print(train_data['package_transport_tz'].unique())\n",
        "print(train_data['package_sightseeing'].unique())\n",
        "print(train_data['package_guided_tour'].unique())\n",
        "print(train_data['package_insurance'].unique())\n",
        "print(train_data['payment_mode'].unique())\n",
        "\n",
        "\n",
        "\n",
        "# Impute missing values in numerical columns\n",
        "numerical_imputer = SimpleImputer(strategy='median')\n",
        "X_train[numerical_cols] = numerical_imputer.fit_transform(X_train[numerical_cols])\n",
        "X_val[numerical_cols] = numerical_imputer.transform(X_val[numerical_cols])\n",
        "test_data[numerical_cols] = numerical_imputer.transform(test_data[numerical_cols])\n",
        "\n",
        "# Impute missing values in categorical columns\n",
        "categorical_imputer = SimpleImputer(strategy='most_frequent')\n",
        "X_train[categorical_cols] = categorical_imputer.fit_transform(X_train[categorical_cols])\n",
        "X_val[categorical_cols] = categorical_imputer.transform(X_val[categorical_cols])\n",
        "test_data[categorical_cols] = categorical_imputer.transform(test_data[categorical_cols])\n",
        "\n",
        "# Convert categorical variables to numeric\n",
        "X_train['age_group'] = X_train['age_group'].map({'45-64':0, '25-44':1,'24-Jan':2, '65+':3})\n",
        "X_val['age_group'] = X_val['age_group'].map({'45-64':0, '25-44':1, '65+':2})\n",
        "test_data['age_group'] = test_data['age_group'].map({'45-64':0, '25-44':1, '65+':2})\n",
        "\n",
        "\n",
        "X_train['travel_with'] = X_train['travel_with'].map({'Friends/Relatives':0, 'Alone':1, 'Spouse':2, 'Children':3, 'Spouse and Children':4 })\n",
        "X_val['travel_with'] = X_val['travel_with'].map({'Friends/Relatives':0, 'Alone':1, 'Spouse':2, 'Children':3, 'Spouse and Children':4})\n",
        "test_data['travel_with'] = test_data['travel_with'].map({'Friends/Relatives':0, 'Alone':1, 'Spouse':2, 'Children':3, 'Spouse and Children':4})\n",
        "\n",
        "X_train['purpose'] = X_train['purpose'].map({'Leisure and Holidays':0, 'Visiting Friends and Relatives':1, 'Business':2,\n",
        " 'Meetings and Conference':3, 'Volunteering':4, 'Scientific and Academic':5,\n",
        " 'Other':6})\n",
        "X_val['purpose'] = X_val['purpose'].map({'Leisure and Holidays':0, 'Visiting Friends and Relatives':1, 'Business':2,\n",
        " 'Meetings and Conference':3, 'Volunteering':4, 'Scientific and Academic':5,\n",
        " 'Other':6})\n",
        "test_data['purpose'] = test_data['purpose'].map({'Leisure and Holidays':0, 'Visiting Friends and Relatives':1, 'Business':2,\n",
        " 'Meetings and Conference':3, 'Volunteering':4, 'Scientific and Academic':5,\n",
        " 'Other':6})\n",
        "\n",
        "X_train['main_activity'] = X_train['main_activity'].map({'Wildlife tourism':0, 'Cultural tourism':1, 'Mountain climbing':2, 'Beach tourism':3,\n",
        " 'Conference tourism':4, 'Hunting tourism':5, 'Bird watching':6, 'business':7,\n",
        " 'Diving and Sport Fishing':8})\n",
        "X_val['main_activity'] = X_val['main_activity'].map({'Wildlife tourism':0, 'Cultural tourism':1, 'Mountain climbing':2, 'Beach tourism':3,\n",
        " 'Conference tourism':4, 'Hunting tourism':5, 'Bird watching':6, 'business':7,\n",
        " 'Diving and Sport Fishing':8})\n",
        "test_data['main_activity'] = test_data['main_activity'].map({'Wildlife tourism':0, 'Cultural tourism':1, 'Mountain climbing':2, 'Beach tourism':3,\n",
        " 'Conference tourism':4, 'Hunting tourism':5, 'Bird watching':6, 'business':7,\n",
        " 'Diving and Sport Fishing':8})\n",
        "\n",
        "X_train['info_source'] = X_train['info_source'].map({'Friends, relatives':0, 'others':1, 'Travel, agent, tour operator':2,\n",
        " 'Radio, TV, Web':3, 'Tanzania Mission Abroad':4, 'inflight magazines':5,\n",
        " 'Newspaper, magazines,brochures':6, 'Trade fair':7})\n",
        "X_val['info_source'] = X_val['info_source'].map({'Friends, relatives':0, 'others':1, 'Travel, agent, tour operator':2,\n",
        " 'Radio, TV, Web':3, 'Tanzania Mission Abroad':4, 'inflight magazines':5,\n",
        " 'Newspaper, magazines,brochures':6, 'Trade fair':7})\n",
        "test_data['info_source'] = test_data['info_source'].map({'Friends, relatives':0, 'others':1, 'Travel, agent, tour operator':2,\n",
        " 'Radio, TV, Web':3, 'Tanzania Mission Abroad':4, 'inflight magazines':5,\n",
        " 'Newspaper, magazines,brochures':6, 'Trade fair':7})\n",
        "\n",
        "X_train['tour_arrangement'] = X_train['tour_arrangement'].map({'Independent':0, 'Package Tour':1})\n",
        "X_val['tour_arrangement'] = X_val['tour_arrangement'].map({'Independent':0, 'Package Tour':1})\n",
        "test_data['tour_arrangement'] = test_data['tour_arrangement'].map({'Independent':0, 'Package Tour':1})\n",
        "\n",
        "X_train['package_transport_int'] = X_train['package_transport_int'].map({'no': 0, 'yes': 1})\n",
        "X_val['package_transport_int'] = X_val['package_transport_int'].map({'no': 0, 'yes': 1})\n",
        "test_data['package_transport_int'] = test_data['package_transport_int'].map({'no': 0, 'yes': 1})\n",
        "\n",
        "X_train['package_accomodation'] = X_train['package_accomodation'].map({'no': 0, 'yes': 1})\n",
        "X_val['package_accomodation'] = X_val['package_accomodation'].map({'no': 0, 'yes': 1})\n",
        "test_data['package_accomodation'] = test_data['package_accomodation'].map({'no': 0, 'yes': 1})\n",
        "\n",
        "X_train['package_food'] = X_train['package_food'].map({'no': 0, 'yes': 1})\n",
        "X_val['package_food'] = X_val['package_food'].map({'no': 0, 'yes': 1})\n",
        "test_data['package_food'] = test_data['package_food'].map({'no': 0, 'yes': 1})\n",
        "\n",
        "X_train['package_transport_tz'] = X_train['package_transport_tz'].map({'no': 0, 'yes': 1})\n",
        "X_val['package_transport_tz'] = X_val['package_transport_tz'].map({'no': 0, 'yes': 1})\n",
        "test_data['package_transport_tz'] = test_data['package_transport_tz'].map({'no': 0, 'yes': 1})\n",
        "\n",
        "X_train['package_sightseeing'] = X_train['package_sightseeing'].map({'no': 0, 'yes': 1})\n",
        "X_val['package_sightseeing'] = X_val['package_sightseeing'].map({'no': 0, 'yes': 1})\n",
        "test_data['package_sightseeing'] = test_data['package_sightseeing'].map({'no': 0, 'yes': 1})\n",
        "\n",
        "X_train['package_guided_tour'] = X_train['package_guided_tour'].map({'no': 0, 'yes': 1})\n",
        "X_val['package_guided_tour'] = X_val['package_guided_tour'].map({'no': 0, 'yes': 1})\n",
        "test_data['package_guided_tour'] = test_data['package_guided_tour'].map({'no': 0, 'yes': 1})\n",
        "\n",
        "X_train['package_insurance'] = X_train['package_insurance'].map({'no': 0, 'yes': 1})\n",
        "X_val['package_insurance'] = X_val['package_insurance'].map({'no': 0, 'yes': 1})\n",
        "test_data['package_insurance'] = test_data['package_insurance'].map({'no': 0, 'yes': 1})\n",
        "\n",
        "\n",
        "X_train['payment_mode'] = X_train['payment_mode'].map({'Cash':0, 'Credit Card':1, 'Other':2, 'Travellers Cheque':3})\n",
        "X_val['payment_mode'] = X_val['payment_mode'].map({'Cash':0, 'Credit Card':1, 'Other':2, 'Travellers Cheque':3})\n",
        "test_data['payment_mode'] = test_data['payment_mode'].map({'Cash':0, 'Credit Card':1, 'Other':2, 'Travellers Cheque':3})\n",
        "\n",
        "# Train the model with hyperparameter tuning\n",
        "param_grid = {\n",
        "    'n_estimators': [100, 200, 300],\n",
        "    'max_depth': [5, 10, None],\n",
        "    'min_samples_split': [2, 5, 10],\n",
        "    'min_samples_leaf': [1, 2, 4],\n",
        "    'max_features': ['sqrt', 'log2', None]\n",
        "}\n",
        "\n",
        "print(train_df.isnull().sum())\n",
        "\n",
        "model = RandomForestRegressor(random_state=42)\n",
        "grid_search = GridSearchCV(model, param_grid, cv=5)\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n",
        "# Retrieve the best model\n",
        "#best_model = grid_search.best_estimator_\n",
        "\n",
        "# Make predictions on the validation set\n",
        "#val_predictions = best_model.predict(X_val)\n",
        "\n",
        "# Evaluate the model\n",
        "#accuracy = accuracy_score(y_val, val_predictions)\n",
        "#print(\"Validation Accuracy:\", accuracy)\n",
        "\n",
        "# Make predictions on the test set\n",
        "#test_predictions = best_model.predict(test_data)\n",
        "\n",
        "# Create a submission file\n",
        "#submission = pd.DataFrame({\n",
        " #   'PassengerId': test_data.index + 892,\n",
        "  #  'Survived': test_predictions\n",
        "#})\n",
        "#submission.to_csv('submission.csv', index=False)"
      ],
      "metadata": {
        "id": "0dR1yYoKvrIb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "9862fb8c-f10a-4cec-c022-8e728fa8470e"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ID                         0\n",
            "country                    0\n",
            "age_group                  0\n",
            "travel_with                0\n",
            "total_female               3\n",
            "total_male                 5\n",
            "purpose                    0\n",
            "main_activity              0\n",
            "info_source                0\n",
            "tour_arrangement           0\n",
            "package_transport_int      0\n",
            "package_accomodation       0\n",
            "package_food               0\n",
            "package_transport_tz       0\n",
            "package_sightseeing        0\n",
            "package_guided_tour        0\n",
            "package_insurance          0\n",
            "night_mainland             0\n",
            "night_zanzibar             0\n",
            "payment_mode               0\n",
            "first_trip_tz              0\n",
            "most_impressing          312\n",
            "total_cost                 0\n",
            "dtype: int64\n",
            "     age_group        travel_with  total_female  total_male  \\\n",
            "0        45-64  Friends/Relatives           1.0         1.0   \n",
            "1        25-44              Alone           1.0         0.0   \n",
            "2        25-44              Alone           0.0         1.0   \n",
            "3        25-44             Spouse           1.0         1.0   \n",
            "5        25-44              Alone           0.0         1.0   \n",
            "...        ...                ...           ...         ...   \n",
            "4802     45-64  Friends/Relatives           2.0         2.0   \n",
            "4804     45-64              Alone           0.0         1.0   \n",
            "4805     25-44             Spouse           1.0         1.0   \n",
            "4807     25-44  Friends/Relatives           1.0         1.0   \n",
            "4808     25-44             Spouse           1.0         1.0   \n",
            "\n",
            "                             purpose     main_activity  \\\n",
            "0               Leisure and Holidays  Wildlife tourism   \n",
            "1               Leisure and Holidays  Cultural tourism   \n",
            "2     Visiting Friends and Relatives  Cultural tourism   \n",
            "3               Leisure and Holidays  Wildlife tourism   \n",
            "5               Leisure and Holidays  Wildlife tourism   \n",
            "...                              ...               ...   \n",
            "4802            Leisure and Holidays  Wildlife tourism   \n",
            "4804                        Business   Hunting tourism   \n",
            "4805            Leisure and Holidays  Wildlife tourism   \n",
            "4807                        Business     Beach tourism   \n",
            "4808            Leisure and Holidays  Wildlife tourism   \n",
            "\n",
            "                       info_source tour_arrangement package_transport_int  \\\n",
            "0               Friends, relatives      Independent                    No   \n",
            "1                           others      Independent                    No   \n",
            "2               Friends, relatives      Independent                    No   \n",
            "3     Travel, agent, tour operator     Package Tour                    No   \n",
            "5     Travel, agent, tour operator     Package Tour                    No   \n",
            "...                            ...              ...                   ...   \n",
            "4802  Travel, agent, tour operator      Independent                    No   \n",
            "4804            Friends, relatives      Independent                    No   \n",
            "4805  Travel, agent, tour operator     Package Tour                   Yes   \n",
            "4807  Travel, agent, tour operator      Independent                   Yes   \n",
            "4808  Travel, agent, tour operator     Package Tour                   Yes   \n",
            "\n",
            "     package_accomodation package_food package_transport_tz  \\\n",
            "0                      No           No                   No   \n",
            "1                      No           No                   No   \n",
            "2                      No           No                   No   \n",
            "3                     Yes          Yes                  Yes   \n",
            "5                      No           No                   No   \n",
            "...                   ...          ...                  ...   \n",
            "4802                   No           No                   No   \n",
            "4804                   No           No                   No   \n",
            "4805                  Yes          Yes                  Yes   \n",
            "4807                  Yes          Yes                   No   \n",
            "4808                  Yes          Yes                  Yes   \n",
            "\n",
            "     package_sightseeing package_guided_tour package_insurance  \\\n",
            "0                     No                  No                No   \n",
            "1                     No                  No                No   \n",
            "2                     No                  No                No   \n",
            "3                    Yes                 Yes                No   \n",
            "5                    Yes                 Yes                No   \n",
            "...                  ...                 ...               ...   \n",
            "4802                  No                  No                No   \n",
            "4804                  No                  No                No   \n",
            "4805                 Yes                 Yes               Yes   \n",
            "4807                  No                  No                No   \n",
            "4808                 Yes                 Yes                No   \n",
            "\n",
            "      night_mainland  night_zanzibar payment_mode  total_cost  \n",
            "0                 13               0         Cash    674602.5  \n",
            "1                 14               7         Cash   3214906.5  \n",
            "2                  1              31         Cash   3315000.0  \n",
            "3                 11               0         Cash   7790250.0  \n",
            "5                  9               3         Cash    120950.0  \n",
            "...              ...             ...          ...         ...  \n",
            "4802              10               5         Cash   6464250.0  \n",
            "4804               2               0  Credit Card   3315000.0  \n",
            "4805              11               0         Cash  10690875.0  \n",
            "4807               5               0  Credit Card   1160250.0  \n",
            "4808               4               7         Cash  13260000.0  \n",
            "\n",
            "[3901 rows x 19 columns]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-1-311e5e5f4528>:69: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
            "  indices_to_drop=train_df[train_data['age_group']=='24-Jan'].index\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "['45-64' '25-44' '24-Jan' '65+']\n",
            "[ 1.  0.  2.  3.  4.  5.  6. nan 15. 17.  7. 10. 12. 44.  9.]\n",
            "[ 1.  0.  2.  4.  3.  5. 12. 10.  6. nan 11.  7. 15.  9. 49.]\n",
            "['Friends/Relatives' 'Alone' 'Spouse' 'Children' 'Spouse and Children']\n",
            "['Leisure and Holidays' 'Visiting Friends and Relatives' 'Business'\n",
            " 'Meetings and Conference' 'Volunteering' 'Scientific and Academic'\n",
            " 'Other']\n",
            "['Wildlife tourism' 'Cultural tourism' 'Mountain climbing' 'Beach tourism'\n",
            " 'Conference tourism' 'Hunting tourism' 'Bird watching' 'business'\n",
            " 'Diving and Sport Fishing']\n",
            "['Friends, relatives' 'others' 'Travel, agent, tour operator'\n",
            " 'Radio, TV, Web' 'Tanzania Mission Abroad' 'inflight magazines'\n",
            " 'Newspaper, magazines,brochures' 'Trade fair']\n",
            "['Independent' 'Package Tour']\n",
            "['No' 'Yes']\n",
            "['No' 'Yes']\n",
            "['No' 'Yes']\n",
            "['No' 'Yes']\n",
            "['No' 'Yes']\n",
            "['No' 'Yes']\n",
            "['No' 'Yes']\n",
            "['Cash' 'Credit Card' 'Other' 'Travellers Cheque']\n",
            "age_group                0\n",
            "travel_with              0\n",
            "total_female             0\n",
            "total_male               0\n",
            "purpose                  0\n",
            "main_activity            0\n",
            "info_source              0\n",
            "tour_arrangement         0\n",
            "package_transport_int    0\n",
            "package_accomodation     0\n",
            "package_food             0\n",
            "package_transport_tz     0\n",
            "package_sightseeing      0\n",
            "package_guided_tour      0\n",
            "package_insurance        0\n",
            "night_mainland           0\n",
            "night_zanzibar           0\n",
            "payment_mode             0\n",
            "total_cost               0\n",
            "dtype: int64\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "\nAll the 1215 fits failed.\nIt is very likely that your model is misconfigured.\nYou can try to debug the error by setting error_score='raise'.\n\nBelow are more details about the failures:\n--------------------------------------------------------------------------------\n1215 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py\", line 345, in fit\n    X, y = self._validate_data(\n  File \"/usr/local/lib/python3.10/dist-packages/sklearn/base.py\", line 584, in _validate_data\n    X, y = check_X_y(X, y, **check_params)\n  File \"/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py\", line 1106, in check_X_y\n    X = check_array(\n  File \"/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py\", line 921, in check_array\n    _assert_all_finite(\n  File \"/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py\", line 161, in _assert_all_finite\n    raise ValueError(msg_err)\nValueError: Input X contains NaN.\nRandomForestRegressor does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-311e5e5f4528>\u001b[0m in \u001b[0;36m<cell line: 197>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    195\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mRandomForestRegressor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m42\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    196\u001b[0m \u001b[0mgrid_search\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGridSearchCV\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam_grid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 197\u001b[0;31m \u001b[0mgrid_search\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    198\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    199\u001b[0m \u001b[0;31m# Retrieve the best model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    872\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    873\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 874\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    875\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    876\u001b[0m             \u001b[0;31m# multimetric is determined here because in the case of a callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36m_run_search\u001b[0;34m(self, evaluate_candidates)\u001b[0m\n\u001b[1;32m   1386\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1387\u001b[0m         \u001b[0;34m\"\"\"Search all candidates in param_grid\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1388\u001b[0;31m         \u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mParameterGrid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1389\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1390\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mevaluate_candidates\u001b[0;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[1;32m    849\u001b[0m                     )\n\u001b[1;32m    850\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 851\u001b[0;31m                 \u001b[0m_warn_or_raise_about_fit_failures\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merror_score\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    852\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    853\u001b[0m                 \u001b[0;31m# For callable self.scoring, the return type is only know after\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36m_warn_or_raise_about_fit_failures\u001b[0;34m(results, error_score)\u001b[0m\n\u001b[1;32m    365\u001b[0m                 \u001b[0;34mf\"Below are more details about the failures:\\n{fit_errors_summary}\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    366\u001b[0m             )\n\u001b[0;32m--> 367\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_fits_failed_message\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    368\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    369\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: \nAll the 1215 fits failed.\nIt is very likely that your model is misconfigured.\nYou can try to debug the error by setting error_score='raise'.\n\nBelow are more details about the failures:\n--------------------------------------------------------------------------------\n1215 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py\", line 345, in fit\n    X, y = self._validate_data(\n  File \"/usr/local/lib/python3.10/dist-packages/sklearn/base.py\", line 584, in _validate_data\n    X, y = check_X_y(X, y, **check_params)\n  File \"/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py\", line 1106, in check_X_y\n    X = check_array(\n  File \"/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py\", line 921, in check_array\n    _assert_all_finite(\n  File \"/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py\", line 161, in _assert_all_finite\n    raise ValueError(msg_err)\nValueError: Input X contains NaN.\nRandomForestRegressor does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "9tZiQs0QvrE3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Ir05u4R5vrBB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "imsyCAw-vq9S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "X0NCUwnuvq4u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Aj0CA_CPvq07"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "nDE_cpRvvqxR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "UVH-Wz9yvqtm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Wrwef0TDvqpM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "MJygREC3vql0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "j6BIhYR7vqi9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "BVP6gmXHvqgG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ERSujr66vqdc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "SYbfGM6nvqaL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "kS7VkNvgvqV4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "TKPfk8wfvqSx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "fj2ABPhyvqPf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "UKwCwFc9vqLH"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}